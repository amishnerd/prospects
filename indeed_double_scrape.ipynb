{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare input and output CSV files\n",
    "CSV_file = \"Rankings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Austin++TX', 'Denver++CO', 'Colorado+Springs++CO', 'Fayetteville++AR', 'Des+Moines++IA', 'Minneapolis-St.+Pau++MN', 'San+Francisco++CA', 'Portland++OR', 'Seattle++WA', 'Raleigh+Durham++NC', 'Huntsville++AL', 'Madison++WI', 'Grand+Rapids++MI', 'San+Jose++CA', 'Nashville++TN', 'Ashville++NC', 'Boise++ID', 'Sarasota++FL', 'Washington,+DC++DC', 'Charlotte++NC', 'Dallas-Fort+Worth++TX', 'Greenville++SC', 'Portland++ME', 'Salt+Lake+City++UT', 'Melbourne++FL', 'Phoenix++AZ', 'Boston++MA', 'Albandy++NY', 'Lexington-Fayette++KY', 'Houston++TX', 'Winston-Salem++NC', 'Omaha++NE', 'Reno++NV', 'San+Antonio++TX', 'Fort+Myers++FL', 'San+Diego++CA', 'Pensacola++FL', 'Indianapolis++IN', 'Cincinnati++OH', 'Fort+Wayne++IN', 'Lansing++MI', 'Jacksonville++FL', 'Manchester++NH', 'Harrisburg++PA', 'Charleston++SC', 'Knoxville++TN', 'Hartford++CT', 'Lancaster++PA', 'Kansas+City++MO', 'Pittsburgh++PA', 'Columbus+++OH', 'Buffalo++NY', 'Richmond++VA', 'Syracuse++NY', 'Chattanooga++TN', 'Tampa++FL', 'Atlanta++GA', 'Rochester++NY', 'Lakeland++FL', 'Honolulu++HI', 'Milwaukee++WI', 'Worchester++MA', 'Orlando++FL', 'Louisville++KY', 'Spokane++WA', 'Greensboro++NC', 'Columbia++SC', 'Oklahoma+City++OK', 'Dayton++OH', 'Anchorage++AK', 'Las+Vegas++NV', 'Augusta++GA', 'Santa+Barbara++CA', 'Santa+Rosa++CA', 'Myrtle+Beach++SC', 'Tucson++AZ', 'Salem++OR', 'Port+St.+Lucie++FL', 'Wichita++KS', 'Springfield++MO', 'St.+Louis++MO', 'Sacramento++CA', 'Tulsa++OK', 'Reading+++PA', 'Cleveland++OH', 'Springfield++MA', 'York++PA', 'Little+Rock++AR', 'Birmingham++AL', 'New+York+City++NY', 'Providence++RI', 'Detroit++MI', 'Allentown+++PA', 'Toledo++OH', 'New+Haven++CT', 'Lafayette++LA', 'Youngstown++OH', 'Scranton++PA', 'Daytona+Beach++FL', 'Baltimore++MD', 'Killeen++TX', 'Philadelphia++PA', 'Virginia+Beach++VA', 'Chicago++IL', 'Corpus+Christi++TX', 'Albuquerque++NM', 'Los+Angeles++CA', 'Beaumont++TX', 'Baton+Rouge++LA', 'El+Paso++TX', 'Jackson++MS', 'McAllen+++TX', 'Miami++FL', 'New+Orleans++LA', 'Flint++MI', 'Brownsville++TX', 'Salinas++CA', 'Memphis++TN', 'Fresno++CA', 'Modesto++CA', 'Mobile++AL', 'Shreveport++LA', 'Stockton++CA', 'Bakersfield++CA', 'San+Juan++PR']\n"
     ]
    }
   ],
   "source": [
    "# Store all cities in a list in City+State format\n",
    "data = pd.read_csv(CSV_file, encoding=\"ISO-8859-1\")\n",
    "data['CityState'] = data.City+'++'+data.State\n",
    "Cities = data['CityState'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "Cities = [city.replace(\" \",\"+\") for city in Cities]\n",
    "print(Cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for city in Cities:\n",
    "#     URL = \"https://www.indeed.com/l-\" + city + \"-jobs.html?foo=1\"\n",
    "#     page = requests.get(URL)\n",
    "\n",
    "#     soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "\n",
    "#     salary_breakdown = soup.find(\"div\", {\"id\" : \"SALARY_rbo\"})\n",
    "#     type_breakdown = soup.find(\"div\", {\"id\" : \"JOB_TYPE_rbo\"})\n",
    "\n",
    "#     salaryLabel = salary_breakdown.findAll(class_ = \"rbLabel\")\n",
    "#     salaryCount = salary_breakdown.findAll(class_ = \"rbCount\")\n",
    "    \n",
    "#     typeLabel = type_breakdown.findAll(class_ = \"rbLabel\")\n",
    "#     typeCount = type_breakdown.findAll(class_ = \"rbCount\")\n",
    "\n",
    "#     salary_labels = [label.text for label in salaryLabel]\n",
    "#     salary_count = [count.text for count in salaryCount]\n",
    "\n",
    "#     type_labels = [label.text for label in typeLabel]\n",
    "#     type_count = [count.text for count in typeCount]\n",
    "\n",
    "#     meta_salary = pd.DataFrame({\n",
    "#         \"City\" : city,\n",
    "#         \"Salary Labels\": salary_labels,\n",
    "#         \"Salary Count\": salary_count,\n",
    "#         \"Type Lable\": type_labels,\n",
    "#         \"Type Count\": type_count\n",
    "#     })\n",
    "    \n",
    "    \n",
    "# print(meta_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'city' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8dfe59ae2d66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m meta_salary = pd.DataFrame({\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[1;34m\"City\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mcity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;34m\"Salary Labels\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msalary_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;34m\"Salary Count\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msalary_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'city' is not defined"
     ]
    }
   ],
   "source": [
    "#     URL = \"https://www.indeed.com/l-\" + \"richmond+VA\" + \"-jobs.html?foo=1\"\n",
    "#     page = requests.get(URL)\n",
    "\n",
    "#     soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "\n",
    "#     salary_breakdown = soup.find(\"div\", {\"id\" : \"SALARY_rbo\"})\n",
    "#     type_breakdown = soup.find(\"div\", {\"id\" : \"JOB_TYPE_rbo\"})\n",
    "\n",
    "#     salaryLabel = salary_breakdown.findAll(class_ = \"rbLabel\")\n",
    "#     salaryCount = salary_breakdown.findAll(class_ = \"rbCount\")\n",
    "    \n",
    "#     typeLabel = type_breakdown.findAll(class_ = \"rbLabel\")\n",
    "#     typeCount = type_breakdown.findAll(class_ = \"rbCount\")\n",
    "\n",
    "#     salary_labels = [label.text for label in salaryLabel]\n",
    "#     salary_count = [count.text for count in salaryCount]\n",
    "\n",
    "#     type_labels = [label.text for label in typeLabel]\n",
    "#     type_count = [count.text for count in typeCount]\n",
    "\n",
    "#     meta_salary = pd.DataFrame({\n",
    "#         \"City\" : city,\n",
    "#         \"Salary Labels\": salary_labels,\n",
    "#         \"Salary Count\": salary_count,\n",
    "#         \"Type Lable\": type_labels,\n",
    "#         \"Type Count\": type_count\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
